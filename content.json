{"pages":[{"title":"关于","text":"一个菜鸟码农的空间🏔 沿途的风景 🐕 家里的小柴犬“卷饼” 🎶 听过的演唱会 🍲 品尝过的美食","link":"/about/index.html"}],"posts":[{"title":"Akka使用教程","text":"Akka 是一个用 Scala 编写的库，用于在 JVM 平台上简化编写具有可容错的、高可伸缩性的 Java 和 Scala 的 Actor 模型应用，其同时提供了Java 和 Scala 的开发接口。Akka 允许我们专注于满足业务需求，而不是编写初级代码。在 Akka 中，Actor 之间通信的唯一机制就是消息传递。Akka 对 Actor 模型的使用提供了一个抽象级别，使得编写正确的并发、并行和分布式系统更加容易。Actor 模型贯穿了整个 Akka 库，为我们提供了一致的理解和使用它们的方法 ActorsIntroduction to Actors待补充","link":"/2022/07/02/Akka%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/"},{"title":"DolphinScheduler源码阅读日记（二）架构设计分析","text":"系统架构 核心概念 table th:first-of-type {width: 25%;} table th:nth-of-type(2) {width: 75%;} 概念 含义 Process Definition 工作流定义 Process Instance 工作流实例，实际运行时会被包装为WorkflowExecuteRunnable Command 事件消息 关键流程分析MasterServer调度工作流流程 以下流程都在MasterServer中执行，不再在标题中赘述 拉取事件MasterSchedulerBootstrap是用于从MySQL中拉取事件（Command）的主要线程，在MasterServer启动时启动，通过findCommands()方法找到待执行的事件，这里的事件不仅限于开始执行工作流，还有其他类型，具体参考CommandType的定义，如下 而拉取事件流程中，如下 采用无中心节点设计，所以每个节点通过取模的方式获取当前节点应该处理的事件。节点总数和当前节点的序号是如何生成的呢？从注册中心（ZK/ETCD/JDBC）获取所有节点列表，在本地生成序号，详情参考org.apache.dolphinscheduler.service.queue.MasterPriorityQueue.ServerComparator 处理事件，创建工作流处理事件，创建工作流在，如下 而创建工作流具体分为如下几个阶段，ProcessDefinition -&gt; ProcessInstance (WorkflowInstance) -&gt; WorkflowExecuteContext -&gt; WorkflowExecuteRunnable，产生WorkflowExecuteRunnable实例即为最终需要调度的工作流 1234567891011121314// ProcessDefinition -&gt; ProcessInstance(WorkflowInstance)org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteContextFactory#createWorkflowExecuteRunnableContext:56org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteContextFactory#createWorkflowInstance:81org.apache.dolphinscheduler.service.process.ProcessServiceImpl#handleCommand:317org.apache.dolphinscheduler.service.process.ProcessServiceImpl#constructProcessInstance:768org.apache.dolphinscheduler.service.process.ProcessServiceImpl#generateNewProcessInstance:586// ProcessInstance(WorkflowInstance) -&gt; WorkflowExecuteContextorg.apache.dolphinscheduler.server.master.runner.WorkflowExecuteRunnableFactory#createWorkflowExecuteRunnable:79org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteContextFactory#createWorkflowExecuteRunnableContext:67// WorkflowExecuteContext -&gt; WorkflowExecuteRunnableorg.apache.dolphinscheduler.server.master.runner.MasterSchedulerBootstrap#run:137org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteRunnableFactory#createWorkflowExecuteRunnable:80 工作流被创建出来之后会生成一个工作流事件WorkflowEvent，放在内存的阻塞队列workflowEventQueue当中 调度工作流MasterSchedulerBootstrap线程启动后，还会再启动一个WorkflowEventLooper工作流事件处理线程，用于消费上一步放入内存的阻塞队列workflowEventQueue当中的工作流事件WorkflowEvent WorkflowEventLooper线程会使用WorkflowEventHandler处理工作流事件 WorkflowEventHandler会将通过调用WorkflowExecuteRunnable工作流的call()方法，将工作流的启动异步提交到WorkflowExecuteThreadPool线程池中执行 最终调用工作流的submitPostNode()方法，开始执行工作流的节点 解析工作流节点获取待提交的TaskNode列表submitTaskNodeList，并生成对应的TaskInstance实例","link":"/2024/07/28/DolphinScheduler%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E6%97%A5%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%88%86%E6%9E%90/"},{"title":"DolphinScheduler源码阅读日记（一）开发环境搭建","text":"系统环境 环境 版本 系统 macOS 12.2.1/m1 pro JRE Zulu 8.62.0.19-CA-macos-aarch64 Maven 3.8.6 Node 18.4.0 Pnpm 7.3.0 Zookeeper 3.8.4 MySQL 8.0.28 DolphinScheduler 3.2.0 搭建项目开发环境项目下载从github下载源码从dolphinscheduler源码仓库下载源码 12git clone https://github.com/apache/dolphinschedulergit checkout 3.2.0 # 切换到3.2.0分支 Zookeeper下载二进制可执行包 下载Zookeeper 3.8.4二进制可执行包 创建文件&amp;日志目录 解压压缩包，创建data、datalog目录 123cd /Users/jiashaoqi/plugin/zookeepertar -zxvf apache-zookeeper-3.8.4-bin.tar.gzmkdir data datalog 修改配置文件将conf目录下的zoo_sample.cfg文件，复制一份，重命名为zoo.cfg，修改其中数据和日志的配置，如： 123cd ./apache-zookeeper-3.8.4-bin/confcp zoo_sample.cfg zoo.cfgvi zoo.cfg 添加环境变量12vi ~/.bash_profile # 添加内容如下source ~/.bash_profile 启动Zookeeper1zkServer.sh start # 见到如图所示即为启动成功 MySQL数据库配置初始化数据库及账号创建完新数据库dolphinscheduler后，将dolphinscheduler/dolphinscheduler-dao/src/main/resources/sql/dolphinscheduler_mysql.sql下的sql文件直接在MySQL中运行，完成数据库初始化 1234567891011121314151617181920mysql&gt; create database dolphinscheduler;Query OK, 1 row affected (0.01 sec)mysql&gt; create user 'dolphin'@'localhost' identified by 'nihplod';Query OK, 0 rows affected (0.01 sec)mysql&gt; grant all privileges on dolphinscheduler.* to 'dolphin'@'localhost';Query OK, 0 rows affected (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)mysql&gt; use dolphinscheduler;Database changedmysql&gt; source /Users/jiashaoqi/workspace/idea/dolphinscheduler/dolphinscheduler-dao/src/main/resources/sql/dolphinscheduler_mysql.sql;Query OK, 1 row affected (0.00 sec)...Query OK, 1 row affected (0.00 sec) 后端Maven依赖下载通过idea打开项目，下载依赖，这可能需要一段时间 注意：maven下载依赖可能会出现问题，对于下载出错的依赖或者插件，可以到本地maven仓库目录下删除对应的子目录重新下载，如在下载依赖后编译时发生了如下异常 1java: 读取/Users/jiashaoqi/plugin/maven/apache-maven-3.8.6/repo/io/fabric8/kubernetes-model-core/5.10.2/kubernetes-model-core-5.10.2.jar时出错; zip file is empty 所以手动下载依赖kubernetes-model-core 12rm -rfv /Users/jiashaoqi/plugin/maven/apache-maven-3.8.6/repo/io/fabric8/kubernetes-model-core/5.10.2mvn dependency:get -DgroupId=io.fabric8 -DartifactId=kubernetes-model-core -Dversion=5.10.2 修改数据库配置 将dolphinscheduler-bom/pom.xml文件中mysql-connector-java依赖的scope修改为compile 将如下配置文件中的mysql的datasource配置为如下内容12345dolphinscheduler-master/src/main/resources/application.yaml:151dolphinscheduler-alert/dolphinscheduler-alert-server/src/main/resources/application.yaml:93dolphinscheduler-api/src/main/resources/application.yaml:229dolphinscheduler-standalone-server/src/main/resources/application.yaml:305dolphinscheduler-tools/src/main/resources/application.yaml:49 配置名 配置值 datasource.driver-class-name com.mysql.cj.jdbc.Driver datasource.url jdbc:mysql://127.0.0.1:3306/dolphinscheduler datasource.username dolphin datasource.password nihplod 修改日志级别为以下配置增加一行内容 使日志能在命令行中显示 123dolphinscheduler-master/src/main/resources/logback-spring.xmldolphinscheduler-worker/src/main/resources/logback-spring.xmldolphinscheduler-api/src/main/resources/logback-spring.xml 12345&lt;root level=&quot;INFO&quot;&gt;+ &lt;appender-ref ref=&quot;STDOUT&quot;/&gt; &lt;appender-ref ref=&quot;APILOGFILE&quot;/&gt; &lt;appender-ref ref=&quot;SKYWALKING-LOG&quot;/&gt;&lt;/root&gt; 可以再在STDOUT这个appender的pattern上套一个%clr(...)，让日志在控制台上高亮显示，如 12345678910111213&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;120 seconds&quot;&gt;+ &lt;include resource=&quot;org/springframework/boot/logging/logback/defaults.xml&quot; /&gt; &lt;!-- ... --&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder&gt; &lt;pattern&gt;+ %clr([%level] %date{yyyy-MM-dd HH:mm:ss.SSS Z} %logger{96}:[%line] - [WorkflowInstance-%X{workflowInstanceId:-0}][TaskInstance-%X{taskInstanceId:-0}] - %msg%n) &lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- ... --&gt;&lt;/configuration&gt; 编译源代码 运行后端服务参考DolphinScheduler 普通开发模式需要启动三个服务，包括 MasterServer，WorkerServer，ApiApplicationServer MasterServer：在 Intellij IDEA 中执行 org.apache.dolphinscheduler.server.master.MasterServer 中的 main 方法，并配置 VM Options -Dlogging.config=classpath:logback-spring.xml -Ddruid.mysql.usePingMethod=false -Dspring.profiles.active=mysql WorkerServer：在 Intellij IDEA 中执行 org.apache.dolphinscheduler.server.worker.WorkerServer 中的 main 方法，并配置 VM Options -Dlogging.config=classpath:logback-spring.xml -Ddruid.mysql.usePingMethod=false -Dspring.profiles.active=mysql ApiApplicationServer：在 Intellij IDEA 中执行 org.apache.dolphinscheduler.api.ApiApplicationServer 中的 main 方法，并配置 VM Options -Dlogging.config=classpath:logback-spring.xml -Dspring.profiles.active=api,mysql。启动完成可以浏览 Open API 文档，地址为 http://localhost:12345/dolphinscheduler/swagger-ui/index.html 前端安装依赖，运行前端服务123cd dolphinscheduler-uipnpm installpnpm run dev 截止目前，前后端已成功运行起来，浏览器访问 http://localhost:5173 ，并使用默认账户密码 admin/dolphinscheduler123 即可完成登录 完成环境搭建搭建成功效果","link":"/2024/07/27/Dolphinscheduler%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E6%97%A5%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"title":"Flink源码编译","text":"前言学习一下Flink的执行原理，需要在本地编译源码好debug运行。 编译环境 环境 版本 系统 m1 pro macbook pro 14 JRE Zulu 8.62.0.19-CA-macos-aarch64 Flink release-1.12.7-rc1 编译过程1mvn clean package -DskipTests -Dhadoop.version=2.7.1 参考下Building Apache Flink from Source 编译过程中产生如下异常并解决 报错：安装node和npm失败1[ERROR] Failed to execute goal com.github.eirslett:frontend-maven-plugin:1.6:install-node-and-npm (install node and npm) on project flink-runtime-web_2.11: Could not download Node.js: Could not download https://nodejs.org/dist/v10.9.0/node-v10.9.0-darwin-arm64.tar.gz: nodejs.org:443 failed to respond -&gt; [Help 1] 解决方案：参考eirslett/frontend-maven-plugin issue 952，FLINK-23230提到的问题修改flink/flink-runtime-web/pom.xml文件中frontend-maven-plugin的版本为1.11.0，发现还是有443异常，后来发现是maven的settings.xml中配置的proxy走的是sock5，修改成http代理后恢复正常","link":"/2022/07/03/Flink%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91/"},{"title":"pyspark分布式训练","text":"","link":"/2022/07/03/pyspark%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/"},{"title":"分布式事务与CAP理论","text":"待补充","link":"/2022/07/24/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E4%B8%8ECAP%E7%90%86%E8%AE%BA/"}],"tags":[{"name":"Akka","slug":"Akka","link":"/tags/Akka/"},{"name":"分布式","slug":"分布式","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"dolphinscheduler","slug":"dolphinscheduler","link":"/tags/dolphinscheduler/"},{"name":"CAP","slug":"CAP","link":"/tags/CAP/"}],"categories":[{"name":"分布式","slug":"分布式","link":"/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"调度服务","slug":"调度服务","link":"/categories/%E8%B0%83%E5%BA%A6%E6%9C%8D%E5%8A%A1/"}]}